{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Alphabets_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xbox          ybox         width       height         onpix  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            yedgex  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20000\n",
      "Number of classes: letter\n",
      "U    813\n",
      "D    805\n",
      "P    803\n",
      "T    796\n",
      "M    792\n",
      "A    789\n",
      "X    787\n",
      "Y    786\n",
      "N    783\n",
      "Q    783\n",
      "F    775\n",
      "G    773\n",
      "E    768\n",
      "B    766\n",
      "V    764\n",
      "L    761\n",
      "R    758\n",
      "I    755\n",
      "O    753\n",
      "W    752\n",
      "S    748\n",
      "J    747\n",
      "K    739\n",
      "C    736\n",
      "H    734\n",
      "Z    734\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:',df.shape[0])\n",
    "print('Number of classes:',df['letter'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "num_col=df.columns[1:]\n",
    "df[num_col]=scaler.fit_transform(df[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   letter  20000 non-null  object \n",
      " 1   xbox    20000 non-null  float64\n",
      " 2   ybox    20000 non-null  float64\n",
      " 3   width   20000 non-null  float64\n",
      " 4   height  20000 non-null  float64\n",
      " 5   onpix   20000 non-null  float64\n",
      " 6   xbar    20000 non-null  float64\n",
      " 7   ybar    20000 non-null  float64\n",
      " 8   x2bar   20000 non-null  float64\n",
      " 9   y2bar   20000 non-null  float64\n",
      " 10  xybar   20000 non-null  float64\n",
      " 11  x2ybar  20000 non-null  float64\n",
      " 12  xy2bar  20000 non-null  float64\n",
      " 13  xedge   20000 non-null  float64\n",
      " 14  xedgey  20000 non-null  float64\n",
      " 15  yedge   20000 non-null  float64\n",
      " 16  yedgex  20000 non-null  float64\n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "x = df.drop('letter', axis=1)\n",
    "y = df['letter']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 16) (4000, 16) (16000,) (4000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marut\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0396 - loss: 0.0730 - val_accuracy: 0.0382 - val_loss: 1.1949e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: 7.8762e-06 - val_accuracy: 0.0382 - val_loss: 2.8476e-06\n",
      "Epoch 3/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: 2.4630e-06 - val_accuracy: 0.0382 - val_loss: 1.1545e-06\n",
      "Epoch 4/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0370 - loss: 9.1115e-07 - val_accuracy: 0.0382 - val_loss: 5.4731e-07\n",
      "Epoch 5/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: 4.0627e-07 - val_accuracy: 0.0382 - val_loss: 2.7463e-07\n",
      "Epoch 6/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: 1.9401e-07 - val_accuracy: 0.0382 - val_loss: 1.3451e-07\n",
      "Epoch 7/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: 1.2348e-07 - val_accuracy: 0.0382 - val_loss: 6.0003e-08\n",
      "Epoch 8/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0417 - loss: 3.5989e-08 - val_accuracy: 0.0382 - val_loss: 1.3363e-08\n",
      "Epoch 9/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0371 - loss: 4.2904e-09 - val_accuracy: 0.0382 - val_loss: -1.4025e-08\n",
      "Epoch 10/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0374 - loss: -2.0249e-08 - val_accuracy: 0.0382 - val_loss: -3.0655e-08\n",
      "Epoch 11/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0400 - loss: -3.2373e-08 - val_accuracy: 0.0382 - val_loss: -4.1294e-08\n",
      "Epoch 12/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -4.8713e-08 - val_accuracy: 0.0382 - val_loss: -4.7851e-08\n",
      "Epoch 13/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0371 - loss: -5.3083e-08 - val_accuracy: 0.0382 - val_loss: -5.1874e-08\n",
      "Epoch 14/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0386 - loss: -5.5475e-08 - val_accuracy: 0.0382 - val_loss: -5.4258e-08\n",
      "Epoch 15/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.0461e-08 - val_accuracy: 0.0382 - val_loss: -5.6136e-08\n",
      "Epoch 16/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0380 - loss: -5.9662e-08 - val_accuracy: 0.0382 - val_loss: -5.7209e-08\n",
      "Epoch 17/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0357 - loss: -6.1947e-08 - val_accuracy: 0.0382 - val_loss: -5.8043e-08\n",
      "Epoch 18/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0370 - loss: -6.3167e-08 - val_accuracy: 0.0382 - val_loss: -5.8490e-08\n",
      "Epoch 19/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.3834e-08 - val_accuracy: 0.0382 - val_loss: -5.8937e-08\n",
      "Epoch 20/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -6.4097e-08 - val_accuracy: 0.0382 - val_loss: -5.9176e-08\n",
      "Epoch 21/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.5403e-08 - val_accuracy: 0.0382 - val_loss: -5.9474e-08\n",
      "Epoch 22/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0367 - loss: -6.2587e-08 - val_accuracy: 0.0382 - val_loss: -5.9682e-08\n",
      "Epoch 23/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -6.1163e-08 - val_accuracy: 0.0382 - val_loss: -5.9772e-08\n",
      "Epoch 24/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0418 - loss: -6.7164e-08 - val_accuracy: 0.0382 - val_loss: -5.9802e-08\n",
      "Epoch 25/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0394 - loss: -6.1645e-08 - val_accuracy: 0.0382 - val_loss: -5.9831e-08\n",
      "Epoch 26/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0375 - loss: -6.7550e-08 - val_accuracy: 0.0382 - val_loss: -5.9831e-08\n",
      "Epoch 27/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0403 - loss: -6.3815e-08 - val_accuracy: 0.0382 - val_loss: -5.9831e-08\n",
      "Epoch 28/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0355 - loss: -6.2836e-08 - val_accuracy: 0.0382 - val_loss: -5.9831e-08\n",
      "Epoch 29/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0355 - loss: -6.2849e-08 - val_accuracy: 0.0382 - val_loss: -5.9831e-08\n",
      "Epoch 30/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -6.1483e-08 - val_accuracy: 0.0382 - val_loss: -5.9861e-08\n",
      "Epoch 31/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0416 - loss: -6.3404e-08 - val_accuracy: 0.0382 - val_loss: -5.9921e-08\n",
      "Epoch 32/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -6.3168e-08 - val_accuracy: 0.0382 - val_loss: -5.9921e-08\n",
      "Epoch 33/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0398 - loss: -6.6959e-08 - val_accuracy: 0.0382 - val_loss: -5.9951e-08\n",
      "Epoch 34/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0383 - loss: -6.3307e-08 - val_accuracy: 0.0382 - val_loss: -5.9980e-08\n",
      "Epoch 35/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0383 - loss: -6.3763e-08 - val_accuracy: 0.0382 - val_loss: -5.9980e-08\n",
      "Epoch 36/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -6.8596e-08 - val_accuracy: 0.0382 - val_loss: -6.0010e-08\n",
      "Epoch 37/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -6.4693e-08 - val_accuracy: 0.0382 - val_loss: -6.0010e-08\n",
      "Epoch 38/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -6.4299e-08 - val_accuracy: 0.0382 - val_loss: -6.0010e-08\n",
      "Epoch 39/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0407 - loss: -6.0394e-08 - val_accuracy: 0.0382 - val_loss: -6.0010e-08\n",
      "Epoch 40/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.2469e-08 - val_accuracy: 0.0382 - val_loss: -6.0010e-08\n",
      "Epoch 41/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0384 - loss: -6.1874e-08 - val_accuracy: 0.0382 - val_loss: -6.0010e-08\n",
      "Epoch 42/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -6.5271e-08 - val_accuracy: 0.0382 - val_loss: -6.0010e-08\n",
      "Epoch 43/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -6.3369e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 44/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: -6.0076e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 45/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0370 - loss: -6.5994e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 46/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0392 - loss: -6.9562e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 47/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0413 - loss: -6.5450e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 48/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0357 - loss: -6.4019e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 49/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.5910e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 50/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0388 - loss: -6.1607e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 51/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -6.5962e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 52/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0395 - loss: -6.3507e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 53/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.2770e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 54/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0404 - loss: -6.6973e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 55/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -6.4214e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 56/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0402 - loss: -6.4790e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 57/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0400 - loss: -5.7905e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 58/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0361 - loss: -6.1338e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 59/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0365 - loss: -6.3401e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 60/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0373 - loss: -6.6620e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 61/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0391 - loss: -6.8795e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 62/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.5674e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 63/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -6.4745e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 64/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0351 - loss: -6.6392e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 65/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0384 - loss: -6.3544e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 66/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0368 - loss: -6.4645e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 67/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0380 - loss: -6.3926e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 68/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0377 - loss: -6.4461e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 69/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0386 - loss: -6.3191e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 70/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0409 - loss: -6.3517e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 71/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0401 - loss: -6.4760e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 72/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0376 - loss: -6.4386e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 73/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0389 - loss: -6.6819e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 74/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0391 - loss: -6.7706e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 75/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -6.1913e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 76/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0368 - loss: -6.1846e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 77/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0409 - loss: -6.3079e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 78/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -6.4194e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 79/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0377 - loss: -6.3489e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 80/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0375 - loss: -6.4610e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 81/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0369 - loss: -6.4929e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 82/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.6658e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0358 - loss: -6.1956e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0378 - loss: -6.1657e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 85/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0401 - loss: -6.3862e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0374 - loss: -6.1629e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 87/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.5938e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 88/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0433 - loss: -6.5830e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 89/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0383 - loss: -6.3914e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 90/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0379 - loss: -6.5422e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 91/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0365 - loss: -6.0168e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 92/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0355 - loss: -6.4557e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0383 - loss: -6.4768e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0383 - loss: -6.5711e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 95/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0373 - loss: -7.0159e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 96/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0353 - loss: -6.0603e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 97/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0353 - loss: -6.5813e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 98/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0372 - loss: -6.3983e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 99/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0378 - loss: -6.8585e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n",
      "Epoch 100/100\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0386 - loss: -6.5622e-08 - val_accuracy: 0.0382 - val_loss: -6.0040e-08\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(16,), activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='kl_divergence', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "history=model.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0435 - loss: -5.9738e-08\n",
      "compile_metrics: 3.82%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using Ephos and Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3; 1/9] START batch_size=20, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: 0.0462\n",
      "Epoch 2/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0369 - loss: -6.0928e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0349 - loss: -5.8492e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -5.9259e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0366 - loss: -5.9813e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0375 - loss: -6.5925e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0408 - loss: -6.1332e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -5.9423e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0355 - loss: -6.4334e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0394 - loss: -5.9516e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "[CV 1/3; 1/9] END .....batch_size=20, epochs=10;, score=0.041 total time=  14.4s\n",
      "[CV 2/3; 1/9] START batch_size=20, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0410 - loss: 0.0500\n",
      "Epoch 2/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0405 - loss: -4.5486e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0398 - loss: -4.2421e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -3.9521e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0429 - loss: -4.8982e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0440 - loss: -4.5064e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0398 - loss: -4.4918e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0451 - loss: -4.3878e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: -4.8646e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0414 - loss: -5.5467e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 2/3; 1/9] END .....batch_size=20, epochs=10;, score=0.041 total time=  13.5s\n",
      "[CV 3/3; 1/9] START batch_size=20, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0341 - loss: 0.0451\n",
      "Epoch 2/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0365 - loss: -6.1536e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0377 - loss: -6.7407e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.4404e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0358 - loss: -6.3934e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0380 - loss: -6.6924e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: -6.4803e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0339 - loss: -6.5461e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0352 - loss: -6.9751e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -6.2103e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 3/3; 1/9] END .....batch_size=20, epochs=10;, score=0.037 total time=  12.9s\n",
      "[CV 1/3; 2/9] START batch_size=20, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0358 - loss: 0.0448\n",
      "Epoch 2/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -5.6848e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -5.9054e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0388 - loss: -5.6778e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0389 - loss: -6.2308e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.1498e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.2657e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0354 - loss: -6.3760e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: -6.1085e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0388 - loss: -6.4277e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -5.5328e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0418 - loss: -6.4792e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0383 - loss: -6.6519e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0353 - loss: -5.8143e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0386 - loss: -6.4979e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0364 - loss: -6.3035e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0366 - loss: -5.7703e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0355 - loss: -6.1692e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0358 - loss: -5.8642e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0411 - loss: -6.4220e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "[CV 1/3; 2/9] END .....batch_size=20, epochs=20;, score=0.041 total time=  24.6s\n",
      "[CV 2/3; 2/9] START batch_size=20, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: 0.0496\n",
      "Epoch 2/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0407 - loss: -5.2644e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0394 - loss: -4.7375e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0399 - loss: -4.9615e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0383 - loss: -4.8486e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0404 - loss: -5.0154e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -5.3241e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: -5.2571e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0401 - loss: -5.9369e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0379 - loss: -4.7572e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0388 - loss: -5.5026e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0410 - loss: -5.1629e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0370 - loss: -5.1755e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -5.7884e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0429 - loss: -6.1212e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0402 - loss: -5.5302e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0410 - loss: -6.2098e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0380 - loss: -5.9922e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0409 - loss: -5.8409e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0413 - loss: -6.0721e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 2/3; 2/9] END .....batch_size=20, epochs=20;, score=0.041 total time=  21.3s\n",
      "[CV 3/3; 2/9] START batch_size=20, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0378 - loss: 0.0438\n",
      "Epoch 2/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0386 - loss: -6.0257e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -6.4225e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0380 - loss: -6.7727e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0352 - loss: -6.7421e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -6.9487e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: -6.5091e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0371 - loss: -6.4955e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0370 - loss: -6.7747e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0362 - loss: -6.8649e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0378 - loss: -6.7792e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.0365 - loss: -6.5763e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0355 - loss: -6.7652e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0367 - loss: -6.3625e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0352 - loss: -6.0021e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -6.3896e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0341 - loss: -6.7542e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -6.5710e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0367 - loss: -6.4807e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0371 - loss: -6.5900e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 3/3; 2/9] END .....batch_size=20, epochs=20;, score=0.037 total time=  25.4s\n",
      "[CV 1/3; 3/9] START batch_size=20, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0388 - loss: 0.0413\n",
      "Epoch 2/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0389 - loss: -6.2846e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0345 - loss: -6.4047e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0368 - loss: -6.8541e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0364 - loss: -6.0407e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0384 - loss: -6.7160e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0359 - loss: -6.4120e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: -6.6987e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0376 - loss: -6.9789e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: -6.0797e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -6.1380e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0371 - loss: -6.3607e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -6.2512e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0412 - loss: -6.2357e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0343 - loss: -6.6139e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0384 - loss: -5.9340e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0393 - loss: -5.9801e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0391 - loss: -6.3182e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -6.4245e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0369 - loss: -6.6490e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0391 - loss: -6.3850e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.3822e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0387 - loss: -6.2689e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.3518e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0350 - loss: -6.1865e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0378 - loss: -6.6688e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0389 - loss: -6.1454e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -6.2706e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0360 - loss: -6.3155e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.2156e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -5.9325e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0388 - loss: -6.3592e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0360 - loss: -6.6591e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0368 - loss: -6.4050e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0376 - loss: -6.7450e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0369 - loss: -6.4300e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0388 - loss: -5.9552e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0369 - loss: -6.5453e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0352 - loss: -6.2931e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0399 - loss: -6.0093e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step\n",
      "[CV 1/3; 3/9] END .....batch_size=20, epochs=40;, score=0.041 total time=  42.5s\n",
      "[CV 2/3; 3/9] START batch_size=20, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0382 - loss: 0.0492\n",
      "Epoch 2/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0411 - loss: -5.7509e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0432 - loss: -5.2338e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0405 - loss: -6.1993e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0407 - loss: -5.2127e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.2993e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0399 - loss: -6.2933e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.0407 - loss: -5.7695e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0402 - loss: -5.8541e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0429 - loss: -5.8818e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -5.8275e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0417 - loss: -6.3040e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0394 - loss: -6.2336e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0389 - loss: -5.8554e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0394 - loss: -6.1302e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0387 - loss: -6.2591e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.2126e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0402 - loss: -6.5104e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0421 - loss: -5.9302e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0401 - loss: -5.7654e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.7517e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0414 - loss: -6.2204e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0409 - loss: -6.6972e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0411 - loss: -6.3583e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -6.3349e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0388 - loss: -6.5305e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -6.3545e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0414 - loss: -6.0679e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0382 - loss: -6.3008e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: -6.5707e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0419 - loss: -5.8988e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -6.3081e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0429 - loss: -5.6760e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -6.0298e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0439 - loss: -6.6354e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0411 - loss: -6.1685e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0403 - loss: -6.2955e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0416 - loss: -6.0078e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0422 - loss: -6.1333e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0397 - loss: -6.7928e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 2/3; 3/9] END .....batch_size=20, epochs=40;, score=0.041 total time=  41.7s\n",
      "[CV 3/3; 3/9] START batch_size=20, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0388 - loss: 0.0428\n",
      "Epoch 2/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: -6.1572e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -6.5488e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0363 - loss: -7.0469e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.0340 - loss: -7.4523e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.0347 - loss: -6.6373e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0362 - loss: -6.1880e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0390 - loss: -6.8003e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0366 - loss: -6.5793e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0384 - loss: -6.3728e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0369 - loss: -6.4499e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0364 - loss: -6.9513e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0338 - loss: -6.8826e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0360 - loss: -6.0746e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0325 - loss: -6.6050e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0357 - loss: -6.8874e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0387 - loss: -6.5226e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0402 - loss: -6.5689e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0349 - loss: -6.7229e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0348 - loss: -5.8264e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0352 - loss: -6.4138e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0359 - loss: -7.3476e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0379 - loss: -6.7098e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0371 - loss: -6.2533e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0362 - loss: -5.9946e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0353 - loss: -5.8514e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0377 - loss: -6.8892e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -7.3554e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0368 - loss: -6.1000e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -6.5944e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: -6.3418e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0354 - loss: -6.4315e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.5949e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0403 - loss: -6.4854e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0388 - loss: -6.5648e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0405 - loss: -6.6696e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0354 - loss: -7.1765e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0370 - loss: -6.4972e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0355 - loss: -6.2908e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0412 - loss: -6.3323e-08\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 3/3; 3/9] END .....batch_size=20, epochs=40;, score=0.037 total time=  36.5s\n",
      "[CV 1/3; 4/9] START batch_size=25, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0411 - loss: 0.0487\n",
      "Epoch 2/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0397 - loss: -6.7388e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0387 - loss: -6.2681e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0380 - loss: -6.1382e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0327 - loss: -6.2410e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0371 - loss: -6.0931e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.3592e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0419 - loss: -6.3940e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0382 - loss: -6.2397e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0407 - loss: -6.7923e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 1/3; 4/9] END .....batch_size=25, epochs=10;, score=0.041 total time=   8.6s\n",
      "[CV 2/3; 4/9] START batch_size=25, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0376 - loss: 0.0537\n",
      "Epoch 2/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0400 - loss: -6.3085e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0390 - loss: -5.8484e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0431 - loss: -6.0873e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0391 - loss: -5.9697e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0394 - loss: -6.3344e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0407 - loss: -6.2019e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0415 - loss: -5.7737e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0387 - loss: -5.6548e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0396 - loss: -6.4596e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 2/3; 4/9] END .....batch_size=25, epochs=10;, score=0.041 total time=   7.1s\n",
      "[CV 3/3; 4/9] START batch_size=25, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0369 - loss: 0.0580\n",
      "Epoch 2/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0383 - loss: -5.5391e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0319 - loss: -5.7216e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0375 - loss: -6.2380e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -5.9670e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0345 - loss: -6.1618e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0438 - loss: -5.5416e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0343 - loss: -5.6560e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0361 - loss: -5.6565e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0352 - loss: -6.3397e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 3/3; 4/9] END .....batch_size=25, epochs=10;, score=0.037 total time=   9.5s\n",
      "[CV 1/3; 5/9] START batch_size=25, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0360 - loss: 0.0538\n",
      "Epoch 2/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: -5.2944e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0366 - loss: -5.6004e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -5.5966e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0389 - loss: -5.3611e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0383 - loss: -6.1827e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: -5.5183e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0373 - loss: -5.4374e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0364 - loss: -5.9411e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0384 - loss: -5.9015e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0370 - loss: -5.5209e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0370 - loss: -6.1370e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -5.5400e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0342 - loss: -5.3719e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0376 - loss: -5.7349e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.0370 - loss: -5.6936e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0390 - loss: -5.6605e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0419 - loss: -6.2003e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -6.4704e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -5.6830e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 1/3; 5/9] END .....batch_size=25, epochs=20;, score=0.041 total time=  15.8s\n",
      "[CV 2/3; 5/9] START batch_size=25, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0401 - loss: 0.0507\n",
      "Epoch 2/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0381 - loss: -6.5665e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0399 - loss: -5.9202e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0391 - loss: -6.1360e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0435 - loss: -6.4690e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0398 - loss: -6.1471e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0409 - loss: -5.9897e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0421 - loss: -6.3868e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0412 - loss: -5.9114e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0432 - loss: -6.3503e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: -6.2841e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0410 - loss: -6.3432e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0427 - loss: -7.0032e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0425 - loss: -6.2536e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0423 - loss: -7.0174e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0415 - loss: -6.5448e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0435 - loss: -5.8931e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0427 - loss: -5.5816e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0416 - loss: -6.1486e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0376 - loss: -6.3271e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 2/3; 5/9] END .....batch_size=25, epochs=20;, score=0.041 total time=  15.2s\n",
      "[CV 3/3; 5/9] START batch_size=25, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: 0.0516\n",
      "Epoch 2/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0380 - loss: -6.3837e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0375 - loss: -6.1584e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0407 - loss: -7.3366e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -6.1897e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0371 - loss: -6.7853e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0367 - loss: -6.8433e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0332 - loss: -6.6857e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0369 - loss: -6.6651e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -6.8659e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0391 - loss: -6.4104e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0360 - loss: -6.6610e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0383 - loss: -6.0477e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0347 - loss: -6.6095e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: -6.9789e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0388 - loss: -6.8760e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0354 - loss: -6.7414e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0357 - loss: -6.7561e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0338 - loss: -6.2301e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -6.7383e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 3/3; 5/9] END .....batch_size=25, epochs=20;, score=0.037 total time=  16.0s\n",
      "[CV 1/3; 6/9] START batch_size=25, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0412 - loss: 0.0516\n",
      "Epoch 2/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0346 - loss: -6.5949e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.0365 - loss: -6.3994e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0356 - loss: -6.8190e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0409 - loss: -6.1853e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0358 - loss: -6.5015e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0380 - loss: -6.3211e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0378 - loss: -6.1358e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0345 - loss: -6.3818e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0383 - loss: -5.9963e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0410 - loss: -6.0763e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0414 - loss: -6.2125e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0355 - loss: -6.6712e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -5.9250e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0374 - loss: -6.1470e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0414 - loss: -6.4275e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0371 - loss: -5.9833e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0383 - loss: -6.4068e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0406 - loss: -6.3458e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0378 - loss: -6.6093e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0386 - loss: -6.4334e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -6.9460e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -6.4481e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.0378 - loss: -6.2084e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0377 - loss: -6.1973e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.1682e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: -5.8335e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.4663e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0349 - loss: -6.3655e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0361 - loss: -6.5513e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0362 - loss: -5.9418e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0375 - loss: -6.6596e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: -6.3818e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0353 - loss: -6.8216e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.2262e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0384 - loss: -6.2919e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0363 - loss: -6.1869e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0334 - loss: -6.3195e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0368 - loss: -6.3000e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: -6.5488e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 1/3; 6/9] END .....batch_size=25, epochs=40;, score=0.041 total time=  30.9s\n",
      "[CV 2/3; 6/9] START batch_size=25, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0392 - loss: 0.0563\n",
      "Epoch 2/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0426 - loss: -5.7463e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -6.0771e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0403 - loss: -5.8890e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0424 - loss: -6.1320e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0423 - loss: -5.7696e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0427 - loss: -6.0253e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0394 - loss: -5.8407e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0409 - loss: -5.6659e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0386 - loss: -6.3107e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -6.0967e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0399 - loss: -5.6973e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0394 - loss: -6.1962e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0409 - loss: -6.3470e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0405 - loss: -6.0288e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0410 - loss: -6.0889e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0409 - loss: -6.1668e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0395 - loss: -5.7546e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0391 - loss: -6.0137e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0422 - loss: -6.3692e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0442 - loss: -6.2147e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0403 - loss: -5.6925e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -5.9144e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0405 - loss: -5.9458e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0413 - loss: -6.3009e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0363 - loss: -5.8447e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0424 - loss: -6.4595e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0420 - loss: -6.1939e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0371 - loss: -5.4778e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0394 - loss: -5.8170e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0406 - loss: -7.1613e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0398 - loss: -5.7842e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0405 - loss: -6.5044e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0401 - loss: -6.1831e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0398 - loss: -6.4778e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0409 - loss: -6.4496e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0402 - loss: -6.4134e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0407 - loss: -6.2533e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.0385 - loss: -6.1564e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0422 - loss: -6.3267e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 2/3; 6/9] END .....batch_size=25, epochs=40;, score=0.041 total time=  32.7s\n",
      "[CV 3/3; 6/9] START batch_size=25, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: 0.0485\n",
      "Epoch 2/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -6.6643e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0360 - loss: -6.8698e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0347 - loss: -7.1705e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -6.9972e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0376 - loss: -6.8256e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0363 - loss: -6.6501e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0380 - loss: -6.6653e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0359 - loss: -7.1262e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0352 - loss: -6.9541e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0358 - loss: -6.2289e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0362 - loss: -6.1966e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0367 - loss: -6.3585e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0330 - loss: -6.3307e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0328 - loss: -6.4292e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0379 - loss: -6.3396e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0371 - loss: -6.6105e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0378 - loss: -6.5131e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0384 - loss: -6.5979e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.1943e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -6.3665e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.3958e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0378 - loss: -6.7663e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0364 - loss: -6.3204e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0355 - loss: -6.8166e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0386 - loss: -6.9145e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0357 - loss: -6.9317e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0367 - loss: -6.4739e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -6.5608e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0401 - loss: -6.6603e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0383 - loss: -7.2163e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0353 - loss: -6.8803e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0348 - loss: -6.9965e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0343 - loss: -6.5153e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -6.8671e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -6.9975e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -6.5862e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0347 - loss: -7.2638e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.7897e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0333 - loss: -6.8503e-08\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 3/3; 6/9] END .....batch_size=25, epochs=40;, score=0.037 total time=  39.0s\n",
      "[CV 1/3; 7/9] START batch_size=30, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0392 - loss: 0.0593\n",
      "Epoch 2/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0360 - loss: -6.3849e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -6.3338e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0360 - loss: -6.7727e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0397 - loss: -6.1619e-08 \n",
      "Epoch 6/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0344 - loss: -6.5748e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0365 - loss: -6.2450e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0343 - loss: -6.3847e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0374 - loss: -6.7030e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0373 - loss: -6.2246e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 1/3; 7/9] END .....batch_size=30, epochs=10;, score=0.041 total time=   7.8s\n",
      "[CV 2/3; 7/9] START batch_size=30, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0380 - loss: 0.0597\n",
      "Epoch 2/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: -6.9430e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0420 - loss: -5.8576e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0439 - loss: -6.0871e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -6.1784e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0413 - loss: -6.1597e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -5.6549e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0399 - loss: -6.2177e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0419 - loss: -6.0797e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0411 - loss: -6.2387e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "[CV 2/3; 7/9] END .....batch_size=30, epochs=10;, score=0.041 total time=   7.3s\n",
      "[CV 3/3; 7/9] START batch_size=30, epochs=10....................................\n",
      "Epoch 1/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0411 - loss: 0.0659\n",
      "Epoch 2/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0363 - loss: -5.4294e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0397 - loss: -5.5100e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0351 - loss: -5.4999e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0361 - loss: -5.6667e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -5.9351e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0369 - loss: -5.1629e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -5.9418e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0383 - loss: -6.0373e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0349 - loss: -5.6126e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "[CV 3/3; 7/9] END .....batch_size=30, epochs=10;, score=0.037 total time=  10.0s\n",
      "[CV 1/3; 8/9] START batch_size=30, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0375 - loss: 0.0605\n",
      "Epoch 2/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0387 - loss: -6.3616e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: -6.2022e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0379 - loss: -6.7243e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.1763e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0406 - loss: -6.2465e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0351 - loss: -6.1569e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0381 - loss: -6.1388e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0389 - loss: -6.4247e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0365 - loss: -6.7077e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0363 - loss: -5.8773e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0375 - loss: -6.3922e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0362 - loss: -6.5919e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0391 - loss: -6.2054e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0358 - loss: -6.3746e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0384 - loss: -6.3135e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0377 - loss: -6.1029e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0394 - loss: -6.3636e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0374 - loss: -6.8568e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0368 - loss: -6.0597e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n",
      "[CV 1/3; 8/9] END .....batch_size=30, epochs=20;, score=0.041 total time=  13.4s\n",
      "[CV 2/3; 8/9] START batch_size=30, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0392 - loss: 0.0654\n",
      "Epoch 2/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -3.5379e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0404 - loss: -4.8472e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0381 - loss: -4.2500e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0435 - loss: -4.1448e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0430 - loss: -3.6779e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0406 - loss: -4.5445e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.0419 - loss: -4.5299e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0412 - loss: -3.9288e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -4.2295e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0410 - loss: -4.5656e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0431 - loss: -3.7299e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -4.8560e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0424 - loss: -4.8810e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0405 - loss: -4.0835e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0414 - loss: -4.2865e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0396 - loss: -5.1757e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0419 - loss: -5.3087e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0360 - loss: -5.2299e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0396 - loss: -4.8077e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "[CV 2/3; 8/9] END .....batch_size=30, epochs=20;, score=0.041 total time=  13.6s\n",
      "[CV 3/3; 8/9] START batch_size=30, epochs=20....................................\n",
      "Epoch 1/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0347 - loss: 0.0607\n",
      "Epoch 2/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0350 - loss: -6.6774e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0374 - loss: -6.5549e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.5465e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.2844e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0352 - loss: -6.4035e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: -6.5843e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0374 - loss: -6.2280e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.0501e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.0397 - loss: -6.6718e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0368 - loss: -6.2607e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -6.7477e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: -6.8717e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0367 - loss: -6.4786e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0386 - loss: -6.4000e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0353 - loss: -6.7066e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.8100e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0358 - loss: -6.8762e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.2950e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0346 - loss: -7.0226e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 3/3; 8/9] END .....batch_size=30, epochs=20;, score=0.037 total time=  14.9s\n",
      "[CV 1/3; 9/9] START batch_size=30, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0367 - loss: 0.0763\n",
      "Epoch 2/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0388 - loss: -3.9888e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0377 - loss: -3.3227e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -4.0342e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -4.6685e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -4.6469e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -3.4581e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -4.7598e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0393 - loss: -4.9755e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0378 - loss: -4.8546e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0375 - loss: -4.2211e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: -3.6686e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0406 - loss: -3.5288e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0376 - loss: -3.7746e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0398 - loss: -4.6910e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.0383 - loss: -4.3490e-08 \n",
      "Epoch 17/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0407 - loss: -4.8006e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0411 - loss: -5.0870e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0363 - loss: -4.4161e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -4.6578e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0361 - loss: -5.5024e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0396 - loss: -5.7534e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0343 - loss: -4.6651e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0384 - loss: -5.1739e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0384 - loss: -5.8355e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0370 - loss: -5.1747e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0342 - loss: -5.7910e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0367 - loss: -5.7916e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0375 - loss: -6.4561e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.0147e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0397 - loss: -6.8289e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0399 - loss: -5.7119e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0351 - loss: -6.4405e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -6.0257e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0391 - loss: -5.6340e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0358 - loss: -6.4748e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0371 - loss: -6.3370e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0374 - loss: -6.1296e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0363 - loss: -5.9434e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0381 - loss: -6.6972e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[CV 1/3; 9/9] END .....batch_size=30, epochs=40;, score=0.041 total time=  31.1s\n",
      "[CV 2/3; 9/9] START batch_size=30, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: 0.0609\n",
      "Epoch 2/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0409 - loss: -5.2787e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0390 - loss: -5.7533e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0420 - loss: -5.8371e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0383 - loss: -6.5939e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0413 - loss: -6.4332e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -6.4041e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0386 - loss: -6.9413e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0389 - loss: -5.8831e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0423 - loss: -6.1703e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -6.0707e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0396 - loss: -6.7301e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0410 - loss: -5.8782e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0397 - loss: -6.4981e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0412 - loss: -6.0531e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0397 - loss: -6.0672e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0382 - loss: -5.9741e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -6.4096e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0369 - loss: -6.6295e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -5.6671e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0437 - loss: -6.2202e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -6.0657e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0384 - loss: -6.3840e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0405 - loss: -6.0082e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: -6.5340e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0401 - loss: -6.2892e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0400 - loss: -6.2054e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0412 - loss: -5.9172e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -6.6275e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0426 - loss: -6.3812e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0415 - loss: -6.0414e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0408 - loss: -5.9924e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0406 - loss: -6.2092e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0401 - loss: -6.0740e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0392 - loss: -6.3356e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0436 - loss: -6.8023e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0378 - loss: -6.5076e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0400 - loss: -6.2584e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -6.8407e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0399 - loss: -6.2868e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[CV 2/3; 9/9] END .....batch_size=30, epochs=40;, score=0.041 total time=  32.9s\n",
      "[CV 3/3; 9/9] START batch_size=30, epochs=40....................................\n",
      "Epoch 1/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: 0.0599\n",
      "Epoch 2/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0352 - loss: -6.5891e-08\n",
      "Epoch 3/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0367 - loss: -6.3310e-08\n",
      "Epoch 4/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0370 - loss: -6.8343e-08\n",
      "Epoch 5/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0373 - loss: -6.6965e-08\n",
      "Epoch 6/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0344 - loss: -6.7170e-08\n",
      "Epoch 7/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0344 - loss: -7.1207e-08\n",
      "Epoch 8/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0385 - loss: -5.8560e-08\n",
      "Epoch 9/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.0356 - loss: -7.2989e-08\n",
      "Epoch 10/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0411 - loss: -6.8979e-08\n",
      "Epoch 11/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0379 - loss: -5.9743e-08\n",
      "Epoch 12/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0353 - loss: -6.5227e-08\n",
      "Epoch 13/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0361 - loss: -6.2225e-08\n",
      "Epoch 14/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0361 - loss: -6.1466e-08\n",
      "Epoch 15/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.1811e-08\n",
      "Epoch 16/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0356 - loss: -6.4364e-08\n",
      "Epoch 17/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0351 - loss: -6.3432e-08\n",
      "Epoch 18/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0364 - loss: -6.7066e-08\n",
      "Epoch 19/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0368 - loss: -6.0402e-08\n",
      "Epoch 20/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0416 - loss: -7.0274e-08\n",
      "Epoch 21/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0329 - loss: -5.7009e-08\n",
      "Epoch 22/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0370 - loss: -6.7858e-08\n",
      "Epoch 23/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0358 - loss: -6.5169e-08\n",
      "Epoch 24/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0378 - loss: -6.0340e-08\n",
      "Epoch 25/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0346 - loss: -6.3693e-08\n",
      "Epoch 26/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0373 - loss: -6.5087e-08\n",
      "Epoch 27/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0350 - loss: -6.5579e-08\n",
      "Epoch 28/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0385 - loss: -6.6608e-08\n",
      "Epoch 29/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0354 - loss: -6.7667e-08\n",
      "Epoch 30/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0373 - loss: -6.4157e-08\n",
      "Epoch 31/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.0354 - loss: -6.4558e-08\n",
      "Epoch 32/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -7.0137e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0356 - loss: -6.4683e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0374 - loss: -6.3043e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0349 - loss: -6.8919e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0371 - loss: -6.4937e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0363 - loss: -6.5478e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0374 - loss: -6.0690e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0380 - loss: -6.8100e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0349 - loss: -6.9904e-08\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step\n",
      "[CV 3/3; 9/9] END .....batch_size=30, epochs=40;, score=0.037 total time=  25.9s\n",
      "Epoch 1/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0389 - loss: 0.0317\n",
      "Epoch 2/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0401 - loss: -6.8329e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0397 - loss: -6.0959e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0414 - loss: -6.7726e-08\n",
      "Epoch 5/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0372 - loss: -6.6202e-08\n",
      "Epoch 6/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0372 - loss: -6.5215e-08\n",
      "Epoch 7/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0394 - loss: -6.4072e-08\n",
      "Epoch 8/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0384 - loss: -6.2423e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0395 - loss: -6.5123e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0396 - loss: -6.5200e-08\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential(name='Hypterparameter-Tuning-Dummy')\n",
    "    model.add(Dense(64, input_dim=16, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(32,kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    adam=Adam(learning_rate=0.01)\n",
    "    model.compile(loss='kl_divergence', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "# Create the model\n",
    "from sklearn.model_selection import KFold\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 1)\n",
    "# Define the grid search parameters\n",
    "batch_size = [20,25,30]\n",
    "epochs = [10,20,40]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(n_splits=3),verbose = 10)\n",
    "grid_result = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.03999992219236237, using {'batch_size': 20, 'epochs': 10}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 20, 'epochs': 20}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 20, 'epochs': 40}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 25, 'epochs': 10}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 25, 'epochs': 20}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 25, 'epochs': 40}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 30, 'epochs': 10}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 30, 'epochs': 20}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'batch_size': 30, 'epochs': 40}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using Dropout and learningrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3; 1/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.001.....\n",
      "[CV 1/3; 1/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.001;, score=0.041 total time=   8.4s\n",
      "[CV 2/3; 1/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.001.....\n",
      "[CV 2/3; 1/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.001;, score=0.041 total time=   9.0s\n",
      "[CV 3/3; 1/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.001.....\n",
      "[CV 3/3; 1/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.001;, score=0.037 total time=   5.7s\n",
      "[CV 1/3; 2/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.01......\n",
      "[CV 1/3; 2/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.01;, score=0.041 total time=   8.7s\n",
      "[CV 2/3; 2/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.01......\n",
      "[CV 2/3; 2/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.01;, score=0.041 total time=  10.0s\n",
      "[CV 3/3; 2/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.01......\n",
      "[CV 3/3; 2/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.01;, score=0.037 total time=   6.8s\n",
      "[CV 1/3; 3/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.1.......\n",
      "[CV 1/3; 3/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.1;, score=0.041 total time=   7.2s\n",
      "[CV 2/3; 3/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.1.......\n",
      "[CV 2/3; 3/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.1;, score=0.041 total time=   8.1s\n",
      "[CV 3/3; 3/9] START model__dropout_rate=0.0, optimizer__learning_rate=0.1.......\n",
      "[CV 3/3; 3/9] END model__dropout_rate=0.0, optimizer__learning_rate=0.1;, score=0.037 total time=   7.4s\n",
      "[CV 1/3; 4/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.001.....\n",
      "[CV 1/3; 4/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.001;, score=0.041 total time=   8.6s\n",
      "[CV 2/3; 4/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.001.....\n",
      "[CV 2/3; 4/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.001;, score=0.041 total time=   7.4s\n",
      "[CV 3/3; 4/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.001.....\n",
      "[CV 3/3; 4/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.001;, score=0.037 total time=   7.3s\n",
      "[CV 1/3; 5/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.01......\n",
      "[CV 1/3; 5/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.01;, score=0.041 total time=   6.5s\n",
      "[CV 2/3; 5/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.01......\n",
      "[CV 2/3; 5/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.01;, score=0.041 total time=   8.5s\n",
      "[CV 3/3; 5/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.01......\n",
      "[CV 3/3; 5/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.01;, score=0.037 total time=   7.2s\n",
      "[CV 1/3; 6/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.1.......\n",
      "[CV 1/3; 6/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.1;, score=0.041 total time=   8.0s\n",
      "[CV 2/3; 6/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.1.......\n",
      "[CV 2/3; 6/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.1;, score=0.041 total time=   8.1s\n",
      "[CV 3/3; 6/9] START model__dropout_rate=0.1, optimizer__learning_rate=0.1.......\n",
      "[CV 3/3; 6/9] END model__dropout_rate=0.1, optimizer__learning_rate=0.1;, score=0.037 total time=   6.6s\n",
      "[CV 1/3; 7/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.001.....\n",
      "[CV 1/3; 7/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.001;, score=0.041 total time=   8.4s\n",
      "[CV 2/3; 7/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.001.....\n",
      "[CV 2/3; 7/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.001;, score=0.041 total time=  10.3s\n",
      "[CV 3/3; 7/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.001.....\n",
      "[CV 3/3; 7/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.001;, score=0.037 total time=   9.0s\n",
      "[CV 1/3; 8/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.01......\n",
      "[CV 1/3; 8/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.01;, score=0.041 total time=   7.8s\n",
      "[CV 2/3; 8/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.01......\n",
      "[CV 2/3; 8/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.01;, score=0.041 total time=   8.9s\n",
      "[CV 3/3; 8/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.01......\n",
      "[CV 3/3; 8/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.01;, score=0.037 total time=   7.5s\n",
      "[CV 1/3; 9/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.1.......\n",
      "[CV 1/3; 9/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.1;, score=0.041 total time=   7.0s\n",
      "[CV 2/3; 9/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.1.......\n",
      "[CV 2/3; 9/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.1;, score=0.041 total time=   8.6s\n",
      "[CV 3/3; 9/9] START model__dropout_rate=0.2, optimizer__learning_rate=0.1.......\n",
      "[CV 3/3; 9/9] END model__dropout_rate=0.2, optimizer__learning_rate=0.1;, score=0.037 total time=   7.5s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def create_model(dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_dim = 16,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32,input_dim = 16,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(model=create_model, loss=\"kl_divergence\", optimizer=\"Adam\", epochs=10, batch_size=20, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(optimizer__learning_rate = learning_rate,model__dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(n_splits=3),verbose = 10)\n",
    "grid_result = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.03999992219236237, using {'model__dropout_rate': 0.0, 'optimizer__learning_rate': 0.001}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.0, 'optimizer__learning_rate': 0.001}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.0, 'optimizer__learning_rate': 0.01}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.0, 'optimizer__learning_rate': 0.1}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.1, 'optimizer__learning_rate': 0.001}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.1, 'optimizer__learning_rate': 0.01}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.1, 'optimizer__learning_rate': 0.1}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.2, 'optimizer__learning_rate': 0.001}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.2, 'optimizer__learning_rate': 0.01}\n",
      "0.03999992219236237,0.0019003177813329368 with: {'model__dropout_rate': 0.2, 'optimizer__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using activation function and kernel initilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START model__activation_function=softmax, model__init=uniform....\n",
      "[CV 1/5; 1/12] END model__activation_function=softmax, model__init=uniform;, score=0.041 total time=  20.5s\n",
      "[CV 2/5; 1/12] START model__activation_function=softmax, model__init=uniform....\n",
      "[CV 2/5; 1/12] END model__activation_function=softmax, model__init=uniform;, score=0.043 total time=  22.5s\n",
      "[CV 3/5; 1/12] START model__activation_function=softmax, model__init=uniform....\n",
      "[CV 3/5; 1/12] END model__activation_function=softmax, model__init=uniform;, score=0.044 total time=  21.2s\n",
      "[CV 4/5; 1/12] START model__activation_function=softmax, model__init=uniform....\n",
      "[CV 4/5; 1/12] END model__activation_function=softmax, model__init=uniform;, score=0.036 total time=  24.8s\n",
      "[CV 5/5; 1/12] START model__activation_function=softmax, model__init=uniform....\n",
      "[CV 5/5; 1/12] END model__activation_function=softmax, model__init=uniform;, score=0.036 total time=  21.1s\n",
      "[CV 1/5; 2/12] START model__activation_function=softmax, model__init=normal.....\n",
      "[CV 1/5; 2/12] END model__activation_function=softmax, model__init=normal;, score=0.041 total time=  21.2s\n",
      "[CV 2/5; 2/12] START model__activation_function=softmax, model__init=normal.....\n",
      "[CV 2/5; 2/12] END model__activation_function=softmax, model__init=normal;, score=0.043 total time=  26.5s\n",
      "[CV 3/5; 2/12] START model__activation_function=softmax, model__init=normal.....\n",
      "[CV 3/5; 2/12] END model__activation_function=softmax, model__init=normal;, score=0.044 total time=  15.3s\n",
      "[CV 4/5; 2/12] START model__activation_function=softmax, model__init=normal.....\n",
      "[CV 4/5; 2/12] END model__activation_function=softmax, model__init=normal;, score=0.036 total time=  26.3s\n",
      "[CV 5/5; 2/12] START model__activation_function=softmax, model__init=normal.....\n",
      "[CV 5/5; 2/12] END model__activation_function=softmax, model__init=normal;, score=0.036 total time=  17.2s\n",
      "[CV 1/5; 3/12] START model__activation_function=softmax, model__init=zero.......\n",
      "[CV 1/5; 3/12] END model__activation_function=softmax, model__init=zero;, score=0.041 total time=  18.1s\n",
      "[CV 2/5; 3/12] START model__activation_function=softmax, model__init=zero.......\n",
      "[CV 2/5; 3/12] END model__activation_function=softmax, model__init=zero;, score=0.043 total time=  18.7s\n",
      "[CV 3/5; 3/12] START model__activation_function=softmax, model__init=zero.......\n",
      "[CV 3/5; 3/12] END model__activation_function=softmax, model__init=zero;, score=0.044 total time=  18.8s\n",
      "[CV 4/5; 3/12] START model__activation_function=softmax, model__init=zero.......\n",
      "[CV 4/5; 3/12] END model__activation_function=softmax, model__init=zero;, score=0.036 total time=  20.3s\n",
      "[CV 5/5; 3/12] START model__activation_function=softmax, model__init=zero.......\n",
      "[CV 5/5; 3/12] END model__activation_function=softmax, model__init=zero;, score=0.036 total time=  16.3s\n",
      "[CV 1/5; 4/12] START model__activation_function=relu, model__init=uniform.......\n",
      "[CV 1/5; 4/12] END model__activation_function=relu, model__init=uniform;, score=0.041 total time=  13.2s\n",
      "[CV 2/5; 4/12] START model__activation_function=relu, model__init=uniform.......\n",
      "[CV 2/5; 4/12] END model__activation_function=relu, model__init=uniform;, score=0.043 total time=  15.1s\n",
      "[CV 3/5; 4/12] START model__activation_function=relu, model__init=uniform.......\n",
      "[CV 3/5; 4/12] END model__activation_function=relu, model__init=uniform;, score=0.044 total time=  17.6s\n",
      "[CV 4/5; 4/12] START model__activation_function=relu, model__init=uniform.......\n",
      "[CV 4/5; 4/12] END model__activation_function=relu, model__init=uniform;, score=0.036 total time=  11.1s\n",
      "[CV 5/5; 4/12] START model__activation_function=relu, model__init=uniform.......\n",
      "[CV 5/5; 4/12] END model__activation_function=relu, model__init=uniform;, score=0.036 total time=  11.1s\n",
      "[CV 1/5; 5/12] START model__activation_function=relu, model__init=normal........\n",
      "[CV 1/5; 5/12] END model__activation_function=relu, model__init=normal;, score=0.041 total time=  13.1s\n",
      "[CV 2/5; 5/12] START model__activation_function=relu, model__init=normal........\n",
      "[CV 2/5; 5/12] END model__activation_function=relu, model__init=normal;, score=0.043 total time=  16.1s\n",
      "[CV 3/5; 5/12] START model__activation_function=relu, model__init=normal........\n",
      "[CV 3/5; 5/12] END model__activation_function=relu, model__init=normal;, score=0.044 total time=  13.2s\n",
      "[CV 4/5; 5/12] START model__activation_function=relu, model__init=normal........\n",
      "[CV 4/5; 5/12] END model__activation_function=relu, model__init=normal;, score=0.036 total time=  14.0s\n",
      "[CV 5/5; 5/12] START model__activation_function=relu, model__init=normal........\n",
      "[CV 5/5; 5/12] END model__activation_function=relu, model__init=normal;, score=0.036 total time=  19.6s\n",
      "[CV 1/5; 6/12] START model__activation_function=relu, model__init=zero..........\n",
      "[CV 1/5; 6/12] END model__activation_function=relu, model__init=zero;, score=0.041 total time=  17.7s\n",
      "[CV 2/5; 6/12] START model__activation_function=relu, model__init=zero..........\n",
      "[CV 2/5; 6/12] END model__activation_function=relu, model__init=zero;, score=0.043 total time=  12.1s\n",
      "[CV 3/5; 6/12] START model__activation_function=relu, model__init=zero..........\n",
      "[CV 3/5; 6/12] END model__activation_function=relu, model__init=zero;, score=0.044 total time=  13.7s\n",
      "[CV 4/5; 6/12] START model__activation_function=relu, model__init=zero..........\n",
      "[CV 4/5; 6/12] END model__activation_function=relu, model__init=zero;, score=0.036 total time=  14.9s\n",
      "[CV 5/5; 6/12] START model__activation_function=relu, model__init=zero..........\n",
      "[CV 5/5; 6/12] END model__activation_function=relu, model__init=zero;, score=0.036 total time=  13.2s\n",
      "[CV 1/5; 7/12] START model__activation_function=tanh, model__init=uniform.......\n",
      "[CV 1/5; 7/12] END model__activation_function=tanh, model__init=uniform;, score=0.041 total time=  13.0s\n",
      "[CV 2/5; 7/12] START model__activation_function=tanh, model__init=uniform.......\n",
      "[CV 2/5; 7/12] END model__activation_function=tanh, model__init=uniform;, score=0.043 total time=  13.9s\n",
      "[CV 3/5; 7/12] START model__activation_function=tanh, model__init=uniform.......\n",
      "[CV 3/5; 7/12] END model__activation_function=tanh, model__init=uniform;, score=0.044 total time=  16.3s\n",
      "[CV 4/5; 7/12] START model__activation_function=tanh, model__init=uniform.......\n",
      "[CV 4/5; 7/12] END model__activation_function=tanh, model__init=uniform;, score=0.036 total time=  12.9s\n",
      "[CV 5/5; 7/12] START model__activation_function=tanh, model__init=uniform.......\n",
      "[CV 5/5; 7/12] END model__activation_function=tanh, model__init=uniform;, score=0.036 total time=  11.5s\n",
      "[CV 1/5; 8/12] START model__activation_function=tanh, model__init=normal........\n",
      "[CV 1/5; 8/12] END model__activation_function=tanh, model__init=normal;, score=0.041 total time=  19.2s\n",
      "[CV 2/5; 8/12] START model__activation_function=tanh, model__init=normal........\n",
      "[CV 2/5; 8/12] END model__activation_function=tanh, model__init=normal;, score=0.043 total time=  15.8s\n",
      "[CV 3/5; 8/12] START model__activation_function=tanh, model__init=normal........\n",
      "[CV 3/5; 8/12] END model__activation_function=tanh, model__init=normal;, score=0.044 total time=  12.7s\n",
      "[CV 4/5; 8/12] START model__activation_function=tanh, model__init=normal........\n",
      "[CV 4/5; 8/12] END model__activation_function=tanh, model__init=normal;, score=0.036 total time=  13.4s\n",
      "[CV 5/5; 8/12] START model__activation_function=tanh, model__init=normal........\n",
      "[CV 5/5; 8/12] END model__activation_function=tanh, model__init=normal;, score=0.036 total time=  16.3s\n",
      "[CV 1/5; 9/12] START model__activation_function=tanh, model__init=zero..........\n",
      "[CV 1/5; 9/12] END model__activation_function=tanh, model__init=zero;, score=0.041 total time=  17.0s\n",
      "[CV 2/5; 9/12] START model__activation_function=tanh, model__init=zero..........\n",
      "[CV 2/5; 9/12] END model__activation_function=tanh, model__init=zero;, score=0.043 total time=  12.8s\n",
      "[CV 3/5; 9/12] START model__activation_function=tanh, model__init=zero..........\n",
      "[CV 3/5; 9/12] END model__activation_function=tanh, model__init=zero;, score=0.044 total time=  10.6s\n",
      "[CV 4/5; 9/12] START model__activation_function=tanh, model__init=zero..........\n",
      "[CV 4/5; 9/12] END model__activation_function=tanh, model__init=zero;, score=0.036 total time=  15.1s\n",
      "[CV 5/5; 9/12] START model__activation_function=tanh, model__init=zero..........\n",
      "[CV 5/5; 9/12] END model__activation_function=tanh, model__init=zero;, score=0.036 total time=  14.1s\n",
      "[CV 1/5; 10/12] START model__activation_function=linear, model__init=uniform....\n",
      "[CV 1/5; 10/12] END model__activation_function=linear, model__init=uniform;, score=0.041 total time=  17.0s\n",
      "[CV 2/5; 10/12] START model__activation_function=linear, model__init=uniform....\n",
      "[CV 2/5; 10/12] END model__activation_function=linear, model__init=uniform;, score=0.043 total time=  17.4s\n",
      "[CV 3/5; 10/12] START model__activation_function=linear, model__init=uniform....\n",
      "[CV 3/5; 10/12] END model__activation_function=linear, model__init=uniform;, score=0.044 total time=  12.9s\n",
      "[CV 4/5; 10/12] START model__activation_function=linear, model__init=uniform....\n",
      "[CV 4/5; 10/12] END model__activation_function=linear, model__init=uniform;, score=0.036 total time=  13.6s\n",
      "[CV 5/5; 10/12] START model__activation_function=linear, model__init=uniform....\n",
      "[CV 5/5; 10/12] END model__activation_function=linear, model__init=uniform;, score=0.036 total time=  14.6s\n",
      "[CV 1/5; 11/12] START model__activation_function=linear, model__init=normal.....\n",
      "[CV 1/5; 11/12] END model__activation_function=linear, model__init=normal;, score=0.041 total time=  16.6s\n",
      "[CV 2/5; 11/12] START model__activation_function=linear, model__init=normal.....\n",
      "[CV 2/5; 11/12] END model__activation_function=linear, model__init=normal;, score=0.043 total time=  11.9s\n",
      "[CV 3/5; 11/12] START model__activation_function=linear, model__init=normal.....\n",
      "[CV 3/5; 11/12] END model__activation_function=linear, model__init=normal;, score=0.044 total time=  14.4s\n",
      "[CV 4/5; 11/12] START model__activation_function=linear, model__init=normal.....\n",
      "[CV 4/5; 11/12] END model__activation_function=linear, model__init=normal;, score=0.036 total time=  13.9s\n",
      "[CV 5/5; 11/12] START model__activation_function=linear, model__init=normal.....\n",
      "[CV 5/5; 11/12] END model__activation_function=linear, model__init=normal;, score=0.036 total time=  14.6s\n",
      "[CV 1/5; 12/12] START model__activation_function=linear, model__init=zero.......\n",
      "[CV 1/5; 12/12] END model__activation_function=linear, model__init=zero;, score=0.041 total time=  10.5s\n",
      "[CV 2/5; 12/12] START model__activation_function=linear, model__init=zero.......\n",
      "[CV 2/5; 12/12] END model__activation_function=linear, model__init=zero;, score=0.043 total time=  13.5s\n",
      "[CV 3/5; 12/12] START model__activation_function=linear, model__init=zero.......\n",
      "[CV 3/5; 12/12] END model__activation_function=linear, model__init=zero;, score=0.044 total time=  12.6s\n",
      "[CV 4/5; 12/12] START model__activation_function=linear, model__init=zero.......\n",
      "[CV 4/5; 12/12] END model__activation_function=linear, model__init=zero;, score=0.036 total time=  20.8s\n",
      "[CV 5/5; 12/12] START model__activation_function=linear, model__init=zero.......\n",
      "[CV 5/5; 12/12] END model__activation_function=linear, model__init=zero;, score=0.036 total time=  20.3s\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_dim = 16,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(32,input_dim = 16,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "adam= Adam(learning_rate=0.01)\n",
    "model = KerasClassifier(model=create_model, loss=\"binary_crossentropy\", optimizer=adam, epochs=10, batch_size=10, verbose=0)\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(model__activation_function = activation_function,model__init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.04, using {'model__activation_function': 'softmax', 'model__init': 'uniform'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'softmax', 'model__init': 'uniform'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'softmax', 'model__init': 'normal'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'softmax', 'model__init': 'zero'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'relu', 'model__init': 'uniform'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'relu', 'model__init': 'normal'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'relu', 'model__init': 'zero'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'tanh', 'model__init': 'uniform'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'tanh', 'model__init': 'normal'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'tanh', 'model__init': 'zero'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'linear', 'model__init': 'uniform'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'linear', 'model__init': 'normal'}\n",
      "0.04,0.0034403397361307225 with: {'model__activation_function': 'linear', 'model__init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
